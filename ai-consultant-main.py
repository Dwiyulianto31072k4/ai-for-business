import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationTokenBufferMemory
from langchain.chains import ConversationalRetrievalChain
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader, TextLoader, CSVLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.callbacks import get_openai_callback
from langchain.prompts import PromptTemplate
import os
import uuid
import time
import threading
import hashlib
import pandas as pd
import logging
import tempfile

# ======= ๐ Konfigurasi Logging =======
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ======= ๐ Konfigurasi Streamlit =======
st.set_page_config(
ย ย page_title="AI Business Consultant Pro",

)

# ======= ๐ Fungsi Keamanan =======
def sanitize_filename(filename):
ย ย """Sanitasi nama file untuk keamanan"""
ย ย return hashlib.md5(filename.encode()).hexdigest()

def get_secure_temp_file(uploaded_file):
ย ย """Membuat file sementara dengan nama yang aman"""
ย ย temp_dir = tempfile.gettempdir()
ย ย secure_filename = sanitize_filename(uploaded_file.name)
ย ย extension = os.path.splitext(uploaded_file.name)[1]
ย ย temp_file_path = os.path.join(temp_dir, f"{secure_filename}{extension}")
ย ยย
ย ย with open(temp_file_path, "wb") as f:
ย ย ย ย f.write(uploaded_file.getbuffer())
ย ยย
ย ย # Menambahkan file ke cleanup list
ย ย if "temp_files" not in st.session_state:
ย ย ย ย st.session_state.temp_files = []
ย ย st.session_state.temp_files.append(temp_file_path)
ย ยย
ย ย return temp_file_path

# ======= ๐งน Fungsi Pembersihan =======
def cleanup_temp_files():
ย ย """Membersihkan file sementara saat sesi berakhir"""
ย ย if "temp_files" in st.session_state:
ย ย ย ย for file_path in st.session_state.temp_files:
ย ย ย ย ย ย try:
ย ย ย ย ย ย ย ย if os.path.exists(file_path):
ย ย ย ย ย ย ย ย ย ย os.remove(file_path)
ย ย ย ย ย ย ย ย ย ย logger.info(f"File berhasil dihapus: {file_path}")
ย ย ย ย ย ย except Exception as e:
ย ย ย ย ย ย ย ย logger.error(f"Gagal menghapus file: {file_path} - {str(e)}")
ย ย ย ย st.session_state.temp_files = []

# ======= ๐ผ Fungsi Inisialisasi =======
def initialize_app():
ย ย """Inisialisasi aplikasi dan session state"""
ย ย # Memastikan semua state tersedia
ย ย if "conversation" not in st.session_state:
ย ย ย ย st.session_state.conversation = None
ย ย if "retriever" not in st.session_state:
ย ย ย ย st.session_state.retriever = None
ย ย if "history" not in st.session_state:
ย ย ย ย st.session_state.history = []
ย ย if "file_processed" not in st.session_state:
ย ย ย ย st.session_state.file_processed = False
ย ย if "file_info" not in st.session_state:
ย ย ย ย st.session_state.file_info = {}
ย ย if "token_usage" not in st.session_state:
ย ย ย ย st.session_state.token_usage = {"total_tokens": 0, "prompt_tokens": 0, "completion_tokens": 0}
ย ย if "llm" not in st.session_state:
ย ย ย ย st.session_state.llm = None
ย ย if "memory" not in st.session_state:
ย ย ย ย st.session_state.memory = None

# ======= ๐ Load API Key =======
def load_api_key():
ย ย """Load API key dari secrets atau input user"""
ย ย # Prioritaskan dari secrets
ย ย if "OPENAI_API_KEY" in st.secrets:
ย ย ย ย return st.secrets["OPENAI_API_KEY"]
ย ยย
ย ย # Jika tidak ada di secrets, minta dari user
ย ย api_key = st.sidebar.text_input("๐ OpenAI API Key:", type="password")
ย ย if not api_key:
ย ย ย ย st.sidebar.warning("โ๏ธ Silakan masukkan API Key OpenAI untuk memulai.")
ย ย return api_key

# ======= ๐ค Inisialisasi Model LLM =======
def init_llm(api_key, model_name, temperature=0.7, max_tokens=500):
ย ย """Inisialisasi model LLM"""
ย ย try:
ย ย ย ย llm = ChatOpenAI(
ย ย ย ย ย ย api_key=api_key,
ย ย ย ย ย ย model=model_name,
ย ย ย ย ย ย temperature=temperature,
ย ย ย ย ย ย max_tokens=max_tokens
ย ย ย ย )
ย ย ย ย return llm
ย ย except Exception as e:
ย ย ย ย logger.error(f"Error inisialisasi LLM: {str(e)}")
ย ย ย ย st.error(f"โ Gagal menginisialisasi model AI: {str(e)}")
ย ย ย ย return None

# ======= ๐ง Inisialisasi Memory =======
def init_memory(max_token_limit=3000):
ย ย """Inisialisasi memory dengan batasan token"""
ย ย return ConversationTokenBufferMemory(
ย ย ย ย memory_key="chat_history",
ย ย ย ย return_messages=True,
ย ย ย ย max_token_limit=max_token_limit,
ย ย ย ย llm=st.session_state.llm
ย ย )

# ======= ๐ Proses File =======
def process_file(uploaded_file, chunk_size=500, chunk_overlap=50):
ย ย """Proses file yang diunggah menjadi vector store"""
ย ย try:
ย ย ย ย with st.spinner("๐ Memproses file..."):
ย ย ย ย ย ย start_time = time.time()
ย ย ย ย ย ยย
ย ย ย ย ย ย # Menyimpan file dengan nama yang aman
ย ย ย ย ย ย file_path = get_secure_temp_file(uploaded_file)
ย ย ย ย ย ยย
ย ย ย ย ย ย # Mendeteksi tipe file dan memilih loader yang sesuai
ย ย ย ย ย ย if uploaded_file.name.endswith('.pdf'):
ย ย ย ย ย ย ย ย loader = PyPDFLoader(file_path)
ย ย ย ย ย ย elif uploaded_file.name.endswith('.txt'):
ย ย ย ย ย ย ย ย loader = TextLoader(file_path)
ย ย ย ย ย ย elif uploaded_file.name.endswith('.csv'):
ย ย ย ย ย ย ย ย loader = CSVLoader(file_path)
ย ย ย ย ย ย else:
ย ย ย ย ย ย ย ย st.error("โ Format file tidak didukung. Silakan unggah file PDF, TXT, atau CSV.")
ย ย ย ย ย ย ย ย return None
ย ย ย ย ย ยย
ย ย ย ย ย ย # Load dokumen
ย ย ย ย ย ย documents = loader.load()
ย ย ย ย ย ยย
ย ย ย ย ย ย # Hitung jumlah halaman/baris
ย ย ย ย ย ย doc_count = len(documents)
ย ย ย ย ย ยย
ย ย ย ย ย ย # Gunakan RecursiveCharacterTextSplitter untuk pemisahan teks yang lebih baik
ย ย ย ย ย ย text_splitter = RecursiveCharacterTextSplitter(
ย ย ย ย ย ย ย ย chunk_size=chunk_size,
ย ย ย ย ย ย ย ย chunk_overlap=chunk_overlap,
ย ย ย ย ย ย ย ย separators=["\n\n", "\n", " ", ""]
ย ย ย ย ย ย )
ย ย ย ย ย ยย
ย ย ย ย ย ย # Split dokumen
ย ย ย ย ย ย split_docs = text_splitter.split_documents(documents)
ย ย ย ย ย ยย
ย ย ย ย ย ย # Hitung jumlah chunks
ย ย ย ย ย ย chunk_count = len(split_docs)
ย ย ย ย ย ยย
ย ย ย ย ย ย # Buat embedding dan simpan ke FAISS
ย ย ย ย ย ย with get_openai_callback() as cb:
ย ย ย ย ย ย ย ย embeddings = OpenAIEmbeddings(api_key=st.session_state.api_key)
ย ย ย ย ย ย ย ย vectorstore = FAISS.from_documents(split_docs, embeddings)
ย ย ย ย ย ย ย ยย
ย ย ย ย ย ย ย ย # Update token usage
ย ย ย ย ย ย ย ย st.session_state.token_usage["prompt_tokens"] += cb.prompt_tokens
ย ย ย ย ย ย ย ย st.session_state.token_usage["completion_tokens"] += cb.completion_tokens
ย ย ย ย ย ย ย ย st.session_state.token_usage["total_tokens"] += cb.total_tokens
ย ย ย ย ย ยย
ย ย ย ย ย ย # Simpan informasi file
ย ย ย ย ย ย st.session_state.file_info = {
ย ย ย ย ย ย ย ย "filename": uploaded_file.name,
ย ย ย ย ย ย ย ย "size_mb": round(uploaded_file.size / (1024 * 1024), 2),
ย ย ย ย ย ย ย ย "doc_count": doc_count,
ย ย ย ย ย ย ย ย "chunk_count": chunk_count,
ย ย ย ย ย ย ย ย "processing_time": round(time.time() - start_time, 2)
ย ย ย ย ย ย }
ย ย ย ย ย ยย
ย ย ย ย ย ย # Kembalikan retriever
ย ย ย ย ย ย return vectorstore.as_retriever(
ย ย ย ย ย ย ย ย search_type="similarity",
ย ย ย ย ย ย ย ย search_kwargs={"k": 5}
ย ย ย ย ย ย )
ย ย ย ย ย ยย
ย ย except Exception as e:
ย ย ย ย logger.error(f"Error memproses file: {str(e)}")
ย ย ย ย st.error(f"โ Gagal memproses file: {str(e)}")
ย ย ย ย return None

# ======= ๐ Inisialisasi Chain =======
def init_chain(retriever):
ย ย """Inisialisasi ConversationalRetrievalChain"""
ย ย # Template prompt kustom
ย ย template = """
ย ย Kamu adalah AI Business Consultant yang profesional dan membantu.
ย ยย
ย ย Konten berikut adalah informasi yang relevan yang ditemukan dari dokumen yang diunggah:
ย ย {context}
ย ยย
ย ย Riwayat Percakapan:
ย ย {chat_history}
ย ยย
ย ย Pertanyaan Pengguna: {question}
ย ยย
ย ย Berikan jawaban yang komprehensif, akurat, dan bermanfaat berdasarkan informasi yang diberikan.
ย ย Jika jawaban tidak ditemukan dalam informasi yang tersedia, katakan dengan jujur bahwaย
ย ย kamu tidak dapat menjawab berdasarkan dokumen yang diunggah.
ย ย """
ย ยย
ย ย prompt = PromptTemplate(
ย ย ย ย input_variables=["context", "chat_history", "question"],
ย ย ย ย template=template
ย ย )
ย ยย
ย ย try:
ย ย ย ย chain = ConversationalRetrievalChain.from_llm(
ย ย ย ย ย ย llm=st.session_state.llm,
ย ย ย ย ย ย retriever=retriever,
ย ย ย ย ย ย memory=st.session_state.memory,
ย ย ย ย ย ย combine_docs_chain_kwargs={"prompt": prompt},
ย ย ย ย ย ย return_source_documents=True
ย ย ย ย )
ย ย ย ย return chain
ย ย except Exception as e:
ย ย ย ย logger.error(f"Error inisialisasi chain: {str(e)}")
ย ย ย ย st.error(f"โ Gagal menginisialisasi chain: {str(e)}")
ย ย ย ย return None

# ======= ๐ Proses Internet Search =======
def search_internet(query):
ย ย """Simulasi pencarian internet (implementasi sebenarnya membutuhkan API)"""
ย ย st.info("๐ Mencari di internet...")
ย ย time.sleep(2)ย # Simulasi delay pencarian
ย ยย
ย ย # Implementasi pencarian sebenarnya akan ditambahkan di sini
ย ยย
ย ย return f"Berikut adalah hasil pencarian untuk '{query}':\n\n" + \
ย ย ย ย ย ย"1. Hasil pencarian yang relevan akan ditampilkan di sini.\n" + \
ย ย ย ย ย ย"2. Informasi tambahan dari pencarian web akan diintergrasikan.\n" + \
ย ย ย ย ย ย"3. Pencarian khusus untuk informasi bisnis akan diprioritaskan."

# ======= ๐ Inisialisasi Aplikasi =======
initialize_app()

# ======= ๐ Sidebar =======
with st.sidebar:
ย ย st.image("https://www.svgrepo.com/show/373328/ai.svg", width=100)
ย ย st.title("๐ผ AI Business Consultant")
ย ยย
ย ย # Load API Key
ย ย st.session_state.api_key = load_api_key()
ย ยย
ย ย # Model Selection
ย ย model_options = {
ย ย ย ย "gpt-4": "GPT-4 (Powerful & Accurate)",
ย ย ย ย "gpt-3.5-turbo": "GPT-3.5 Turbo (Fast & Efficient)",
ย ย ย ย "gpt-3.5-turbo-16k": "GPT-3.5 Turbo 16K (Extended Context)"
ย ย }
ย ย selected_model = st.selectbox(
ย ย ย ย "๐ค Pilih Model:",
ย ย ย ย options=list(model_options.keys()),
ย ย ย ย format_func=lambda x: model_options[x]
ย ย )
ย ยย
ย ย # Advanced Settings
ย ย with st.expander("โ๏ธ Pengaturan Lanjutan"):
ย ย ย ย temperature = st.slider("Temperature:", 0.0, 1.0, 0.7, 0.1)
ย ย ย ย max_tokens = st.slider("Max Tokens Response:", 256, 4096, 1024, 128)
ย ย ย ย chunk_size = st.slider("Chunk Size:", 100, 1000, 500, 50)
ย ย ย ย chunk_overlap = st.slider("Chunk Overlap:", 0, 200, 50, 10)
ย ยย
ย ย # Initialize LLM if API key is available
ย ย if st.session_state.api_key and (st.session_state.llm is None orย
ย ย ย ย ย ย ย ย ย ย ย ย ย ย ย ย ย ย ย ยst.session_state.llm.model != selected_model):
ย ย ย ย st.session_state.llm = init_llm(
ย ย ย ย ย ย st.session_state.api_key,
ย ย ย ย ย ย selected_model,
ย ย ย ย ย ย temperature,
ย ย ย ย ย ย max_tokens
ย ย ย ย )
ย ย ย ยย
ย ย ย ย # Reinitialize memory with new LLM
ย ย ย ย if st.session_state.llm:
ย ย ย ย ย ย st.session_state.memory = init_memory()
ย ยย
ย ย # Token Usage Stats
ย ย if st.session_state.token_usage["total_tokens"] > 0:
ย ย ย ย st.write("๐ **Token Usage**")
ย ย ย ย st.write(f"Total: {st.session_state.token_usage['total_tokens']}")
ย ย ย ย st.write(f"Prompt: {st.session_state.token_usage['prompt_tokens']}")
ย ย ย ย st.write(f"Completion: {st.session_state.token_usage['completion_tokens']}")
ย ยย
ย ย # Control Buttons
ย ย col1, col2 = st.columns(2)
ย ย with col1:
ย ย ย ย if st.button("๐ Reset Chat", key="reset"):
ย ย ย ย ย ย st.session_state.history = []
ย ย ย ย ย ย st.session_state.memory = init_memory()
ย ย ย ย ย ย st.success("๐ก Chat telah direset!")
ย ยย
ย ย with col2:
ย ย ย ย if st.button("๐๏ธ Clear Files", key="clear"):
ย ย ย ย ย ย st.session_state.retriever = None
ย ย ย ย ย ย st.session_state.file_processed = False
ย ย ย ย ย ย st.session_state.file_info = {}
ย ย ย ย ย ย cleanup_temp_files()
ย ย ย ย ย ย st.success("๐๏ธ File telah dihapus!")

# ======= ๐น Main Content =======
st.title("๐ผ AI Business Consultant")
st.write("Konsultan bisnis AI yang dapat membantu Anda dengan strategi bisnis, analisis data, dan rekomendasi.")

# Tabs for different modes
tab1, tab2 = st.tabs(["๐ฌ Chat", "๐ Upload File"])

# Upload File Tab
with tab2:
ย ย st.subheader("๐ Unggah Dokumen")
ย ยย
ย ย uploaded_file = st.file_uploader(
ย ย ย ย "๐ Unggah file (PDF, TXT, CSV)",ย
ย ย ย ย type=["pdf", "txt", "csv"],
ย ย ย ย accept_multiple_files=False
ย ย )
ย ยย
ย ย col1, col2 = st.columns(2)
ย ยย
ย ย with col1:
ย ย ย ย process_button = st.button("โ Proses File")
ย ยย
ย ย if process_button and uploaded_file:
ย ย ย ย # Proses file
ย ย ย ย st.session_state.retriever = process_file(
ย ย ย ย ย ย uploaded_file,
ย ย ย ย ย ย chunk_size=chunk_size,
ย ย ย ย ย ย chunk_overlap=chunk_overlap
ย ย ย ย )
ย ย ย ยย
ย ย ย ย if st.session_state.retriever:
ย ย ย ย ย ย st.session_state.file_processed = True
ย ย ย ย ย ย st.session_state.conversation = init_chain(st.session_state.retriever)
ย ย ย ย ย ย st.success("โ File berhasil diproses dan siap digunakan!")
ย ยย
ย ย # Tampilkan informasi file jika sudah diproses
ย ย if st.session_state.file_processed and st.session_state.file_info:
ย ย ย ย st.subheader("๐ Informasi File")
ย ย ย ย info = st.session_state.file_info
ย ย ย ยย
ย ย ย ย col1, col2, col3 = st.columns(3)
ย ย ย ย col1.metric("Nama File", info["filename"])
ย ย ย ย col2.metric("Ukuran", f"{info['size_mb']} MB")
ย ย ย ย col3.metric("Waktu Proses", f"{info['processing_time']} detik")
ย ย ย ยย
ย ย ย ย col1, col2 = st.columns(2)
ย ย ย ย col1.metric("Jumlah Halaman/Baris", info["doc_count"])
ย ย ย ย col2.metric("Jumlah Chunks", info["chunk_count"])

# Chat Tab
with tab1:
ย ย st.subheader("๐ฌ Chat dengan AI Business Consultant")
ย ยย
ย ย # Tampilkan status koneksi file
ย ย if st.session_state.file_processed:
ย ย ย ย st.success(f"๐ File terhubung: {st.session_state.file_info['filename']}")
ย ยย
ย ย # Chat container
ย ย chat_container = st.container()
ย ยย
ย ย # Tampilkan chat history
ย ย with chat_container:
ย ย ย ย for role, message in st.session_state.history:
ย ย ย ย ย ย with st.chat_message(role):
ย ย ย ย ย ย ย ย st.write(message)
ย ยย
ย ย # Disable chat input jika API key tidak tersedia
ย ย if not st.session_state.api_key:
ย ย ย ย st.warning("โ๏ธ Silakan masukkan API Key OpenAI di sidebar untuk memulai chat.")
ย ย ย ย chat_input_disabled = True
ย ย else:
ย ย ย ย chat_input_disabled = False
ย ยย
ย ย # Chat input
ย ย user_input = st.chat_input(
ย ย ย ย "โ๏ธ Ketik pesan Anda...",ย
ย ย ย ย disabled=chat_input_disabled
ย ย )
ย ยย
ย ย if user_input:
ย ย ย ย # Tampilkan pesan user
ย ย ย ย with st.chat_message("user"):
ย ย ย ย ย ย st.write(user_input)
ย ย ย ยย
ย ย ย ย # Tambahkan ke history
ย ย ย ย st.session_state.history.append(("user", user_input))
ย ย ย ยย
ย ย ย ย # Proses pertanyaan
ย ย ย ย with st.spinner("AI sedang berpikir..."):
ย ย ย ย ย ย try:
ย ย ย ย ย ย ย ย # Deteksi jika ada permintaan pencarian web
ย ย ย ย ย ย ย ย if "cari di internet" in user_input.lower() or "search online" in user_input.lower():
ย ย ย ย ย ย ย ย ย ย response = search_internet(user_input)
ย ย ย ย ย ย ย ยย
ย ย ย ย ย ย ย ย # Jika ada file yang diproses, gunakan ConversationalRetrievalChain
ย ย ย ย ย ย ย ย elif st.session_state.file_processed and st.session_state.conversation:
ย ย ย ย ย ย ย ย ย ย with get_openai_callback() as cb:
ย ย ย ย ย ย ย ย ย ย ย ย result = st.session_state.conversation.invoke({
ย ย ย ย ย ย ย ย ย ย ย ย ย ย "question": user_input
ย ย ย ย ย ย ย ย ย ย ย ย })
ย ย ย ย ย ย ย ย ย ย ย ยย
ย ย ย ย ย ย ย ย ย ย ย ย response = result["answer"]
ย ย ย ย ย ย ย ย ย ย ย ยย
ย ย ย ย ย ย ย ย ย ย ย ย # Update token usage
ย ย ย ย ย ย ย ย ย ย ย ย st.session_state.token_usage["prompt_tokens"] += cb.prompt_tokens
ย ย ย ย ย ย ย ย ย ย ย ย st.session_state.token_usage["completion_tokens"] += cb.completion_tokens
ย ย ย ย ย ย ย ย ย ย ย ย st.session_state.token_usage["total_tokens"] += cb.total_tokens
ย ย ย ย ย ย ย ย ย ย ย ยย
ย ย ย ย ย ย ย ย ย ย ย ย # Tambahkan informasi sumber
ย ย ย ย ย ย ย ย ย ย ย ย if "source_documents" in result and result["source_documents"]:
ย ย ย ย ย ย ย ย ย ย ย ย ย ย sources = set()
ย ย ย ย ย ย ย ย ย ย ย ย ย ย for doc in result["source_documents"]:
ย ย ย ย ย ย ย ย ย ย ย ย ย ย ย ย if hasattr(doc, "metadata") and "source" in doc.metadata:
ย ย ย ย ย ย ย ย ย ย ย ย ย ย ย ย ย ย sources.add(doc.metadata["source"])
ย ย ย ย ย ย ย ย ย ย ย ย ย ยย
ย ย ย ย ย ย ย ย ย ย ย ย ย ย if sources:
ย ย ย ย ย ย ย ย ย ย ย ย ย ย ย ย response += "\n\n**Sumber:**\n"
ย ย ย ย ย ย ย ย ย ย ย ย ย ย ย ย for source in sources:
ย ย ย ย ย ย ย ย ย ย ย ย ย ย ย ย ย ย response += f"- {source}\n"
ย ย ย ย ย ย ย ยย
ย ย ย ย ย ย ย ย # Jika tidak ada file, gunakan LLM langsung
ย ย ย ย ย ย ย ย else:
ย ย ย ย ย ย ย ย ย ย with get_openai_callback() as cb:
ย ย ย ย ย ย ย ย ย ย ย ย result = st.session_state.llm.invoke(
ย ย ย ย ย ย ย ย ย ย ย ย ย ย f"Kamu adalah AI Business Consultant yang profesional. Jawab pertanyaan berikut: {user_input}"
ย ย ย ย ย ย ย ย ย ย ย ย )
ย ย ย ย ย ย ย ย ย ย ย ยย
ย ย ย ย ย ย ย ย ย ย ย ย response = result.content
ย ย ย ย ย ย ย ย ย ย ย ยย
ย ย ย ย ย ย ย ย ย ย ย ย # Update token usage
ย ย ย ย ย ย ย ย ย ย ย ย st.session_state.token_usage["prompt_tokens"] += cb.prompt_tokens
ย ย ย ย ย ย ย ย ย ย ย ย st.session_state.token_usage["completion_tokens"] += cb.completion_tokens
ย ย ย ย ย ย ย ย ย ย ย ย st.session_state.token_usage["total_tokens"] += cb.total_tokens
ย ย ย ย ย ย ย ยย
ย ย ย ย ย ย ย ย # Tambahkan respons ke history
ย ย ย ย ย ย ย ย st.session_state.history.append(("assistant", response))
ย ย ย ย ย ย ย ยย
ย ย ย ย ย ย ย ย # Tampilkan respons
ย ย ย ย ย ย ย ย with st.chat_message("assistant"):
ย ย ย ย ย ย ย ย ย ย st.write(response)
ย ย ย ย ย ย ย ย ย ยย
ย ย ย ย ย ย except Exception as e:
ย ย ย ย ย ย ย ย logger.error(f"Error saat memproses pertanyaan: {str(e)}")
ย ย ย ย ย ย ย ย error_message = f"โ๏ธ Terjadi kesalahan: {str(e)}"
ย ย ย ย ย ย ย ย st.error(error_message)
ย ย ย ย ย ย ย ย st.session_state.history.append(("assistant", error_message))

# ======= ๐จ Custom CSS =======
st.markdown("""
<style>
ย ย /* Gaya untuk container */
ย ย .main .block-container {
ย ย ย ย padding-top: 2rem;
ย ย ย ย padding-bottom: 2rem;
ย ย }
ย ยย
ย ย /* Gaya untuk chat messages */
ย ย .stChatMessage {
ย ย ย ย border-radius: 15px;
ย ย ย ย padding: 10px;
ย ย ย ย margin-bottom: 15px;
ย ย }
ย ยย
ย ย /* Gaya untuk pesan user */
ย ย .stChatMessage[data-testid="stChatMessage-user"] {
ย ย ย ย background-color: #E7F3FE;
ย ย ย ย border-left: 5px solid #4285F4;
ย ย }
ย ยย
ย ย /* Gaya untuk pesan assistant */
ย ย .stChatMessage[data-testid="stChatMessage-assistant"] {
ย ย ย ย background-color: #F1F3F4;
ย ย ย ย border-left: 5px solid #34A853;
ย ย }
ย ยย
ย ย /* Gaya untuk chat input */
ย ย .stChatInput {
ย ย ย ย border-radius: 20px;
ย ย ย ย border: 1px solid #DFE1E5;
ย ย ย ย padding: 10px;
ย ย ย ย background-color: #F8F9FA;
ย ย }
ย ยย
ย ย /* Gaya untuk file uploader */
ย ย .stFileUploader {
ย ย ย ย border: 2px dashed #4285F4;
ย ย ย ย border-radius: 10px;
ย ย ย ย padding: 20px;
ย ย ย ย text-align: center;
ย ย ย ย background-color: #F8F9FA;
ย ย }
ย ยย
ย ย /* Gaya untuk tombol */
ย ย .stButton > button {
ย ย ย ย border-radius: 20px;
ย ย ย ย padding: 10px 20px;
ย ย ย ย font-weight: 500;
ย ย ย ย transition: all 0.3s ease;
ย ย }
ย ยย
ย ย .stButton > button:hover {
ย ย ย ย transform: translateY(-2px);
ย ย ย ย box-shadow: 0 4px 8px rgba(0,0,0,0.1);
ย ย }
ย ยย
ย ย /* Gaya untuk metrics */
ย ย .css-1ht1j8u {
ย ย ย ย background-color: #F1F3F4;
ย ย ย ย padding: 10px;
ย ย ย ย border-radius: 10px;
ย ย ย ย box-shadow: 0 2px 5px rgba(0,0,0,0.05);
ย ย }
</style>
""", unsafe_allow_html=True)

# ======= ๐งน Cleanup pada akhir sesi =======
if st.session_state.get("cleanup_registered", False) == False:
ย ย st.session_state.cleanup_registered = True
ย ย threading.Thread(target=cleanup_temp_files).start()
